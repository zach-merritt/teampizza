{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "#ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (4040, 32)\n",
      "Test Shape: (1631, 17)\n"
     ]
    }
   ],
   "source": [
    "#1. Train Data\n",
    "with open('../data/train.json') as fin:\n",
    "    trainjson = json.load(fin)\n",
    "train = pd.io.json.json_normalize(trainjson)\n",
    "#2. Test Data\n",
    "with open('../data/test.json') as fin:\n",
    "    testjson = json.load(fin)\n",
    "test = pd.io.json.json_normalize(testjson)\n",
    "\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4040, 32)\n",
      "data shape:  (4040,)\n",
      "label shape: (4040,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd_train = train\n",
    "pd_test = test\n",
    "\n",
    "\n",
    "np_test = np.array(pd_test)\n",
    "np_train = np.array(pd_train)\n",
    "\n",
    "print(np_train.shape)\n",
    "\n",
    "\n",
    "X = np_train[:,6]\n",
    "Y = np_train[:,22]\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    " X,\n",
    " Y, test_size=0.2, random_state=0)\n",
    "\n",
    "test_data, dev_data, test_labels, dev_labels = train_test_split(\n",
    " test_data,\n",
    " test_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zmerritt\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Baseline:\n",
      "Best Alpha = 0.5  accuracy: 0.734567901235\n",
      "\n",
      "Logistic Regression Baseline:\n",
      "Best C = 0.1  accuracy: 0.740740740741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vect=CountVectorizer()\n",
    "data=vect.fit_transform(train_data).toarray()\n",
    "devdata=vect.transform(dev_data).toarray()\n",
    "\n",
    "\n",
    "#Use np.where to binarize train and dev set where values above and below 0.5.\n",
    "b=train_labels\n",
    "trainlabels=np.where(b==True, 1, 0)\n",
    "\n",
    "bl=dev_labels\n",
    "devlabels=np.where(bl==True, 1, 0)\n",
    "\n",
    "b2=test_labels\n",
    "testlabels=np.where(b2==True, 1, 0)\n",
    "\n",
    "categories = ['Got Pizza', 'Didn\\'t get pizza']\n",
    "\n",
    "print('Baseline Scores...')\n",
    "#Run MultinomialNB Classifier\n",
    "# mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf',MultinomialNB(alpha=0.01))])\n",
    "# mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "# pred = mnb_clf.predict(dev_data)\n",
    "# score1=metrics.accuracy_score(devlabels,pred)\n",
    "# print 'Naive Bayes Score:',score1\n",
    "best_nb = []\n",
    "alphas = [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "for k in range(len(alphas)):\n",
    "    mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf', MultinomialNB(alpha=alphas[k]))])\n",
    "    mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "    pred = mnb_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_nb.append(metrics.accuracy_score(devlabels,pred))\n",
    "bestAlphaAccuracy = max(best_nb)\n",
    "bestAlphaValue = alphas[best_nb.index(bestAlphaAccuracy)]\n",
    "print('Naive Bayes Baseline:')\n",
    "print('Best Alpha =', bestAlphaValue, ' accuracy:', bestAlphaAccuracy)\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "#Run Logistic Regression classifier\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),('lgclf', LogisticRegression(C=0.5))])\n",
    "log_clf = log_clf.fit(train_data, trainlabels) \n",
    "pred = log_clf.predict(dev_data)        \n",
    "score2= metrics.accuracy_score(devlabels,pred)\n",
    "#print 'Logistic Regression Score:',score2\n",
    "best_logit = []\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for k in range(len(C)):\n",
    "    log_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lgclf', LogisticRegression(C=C[k]))]);\n",
    "    log_clf = log_clf.fit(train_data, trainlabels)\n",
    "    pred = log_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_logit.append(metrics.accuracy_score(devlabels,pred))\n",
    "    weights = log_clf.named_steps['lgclf'].coef_\n",
    "bestCAccuracy = max(best_logit)\n",
    "bestCValue = C[best_logit.index(bestCAccuracy)]\n",
    "print('Logistic Regression Baseline:')\n",
    "print('Best C =', bestCValue, ' accuracy:', bestCAccuracy)\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
