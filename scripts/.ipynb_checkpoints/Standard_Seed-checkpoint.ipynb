{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from subprocess import check_output\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (4040, 32)\n",
      "Test Shape: (1631, 17)\n",
      "(3232, 17)\n",
      "(646, 17)\n",
      "(162, 17)\n",
      "(3232,)\n",
      "(646,)\n",
      "(162,)\n"
     ]
    }
   ],
   "source": [
    "#1. Train Data\n",
    "with open('../data/train.json') as fin:\n",
    "   trainjson = json.load(fin)\n",
    "train = pd.io.json.json_normalize(trainjson)\n",
    "#2. Test Data\n",
    "with open('../data/test.json') as fin:\n",
    "   testjson = json.load(fin)\n",
    "test = pd.io.json.json_normalize(testjson)\n",
    "\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "\n",
    "train_labels_master = train[['requester_received_pizza']]\n",
    "train_data_master = train[test.columns & train.columns]\n",
    "train_only_data_master = train[train.columns[~train.columns.isin(test.columns)]].drop(['requester_received_pizza'], axis = 1)\n",
    "\n",
    "#Apply train_test_split twice to get train, test, and dev set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   train_data_master,\n",
    "   train_labels_master.values.ravel(), test_size=0.2, random_state=0)\n",
    "\n",
    "x_test, x_dev, y_test, y_dev = train_test_split(\n",
    "   x_test,\n",
    "   y_test, test_size=0.2, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_dev.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
